{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caguirre5/Lab10-DL/blob/main/Lab10_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Universidad del Valle <br>\n",
        "Deep Learning <br>\n",
        "Integrantes:\n",
        "\n",
        "* Marco Jurado 20308\n",
        "* Diego Cordova 20212\n",
        "* Paola Contreras 20213\n",
        "* Paola de Leon 20361\n",
        "* Cristian Aguirre 20231"
      ],
      "metadata": {
        "id": "gEotDDtU87H5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO4nFAGB8w7h"
      },
      "source": [
        "# Parte 1. Practica"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42iwuooCAUss",
        "outputId": "14b897ce-0f2b-4d21-d7cc-425018b3dcf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Importar librerias"
      ],
      "metadata": {
        "id": "Sn-D4mkvmfp0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WJKnhHdg8w7k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import gymnasium as gym\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Crear el entorno CartPole"
      ],
      "metadata": {
        "id": "ibPe32fnmlGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')"
      ],
      "metadata": {
        "id": "dBwU_1XYAKFQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Definan las redes en línea y de destino"
      ],
      "metadata": {
        "id": "y_c2nb2gmot4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Q_network(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Q_network, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Ju1kijYSAhJV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Hiperparámetros"
      ],
      "metadata": {
        "id": "fFrvztremreX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ur = 0.005 # update rate\n",
        "steps = 0\n",
        "Gamma = 0.999\n",
        "device = \"cpu\"\n",
        "batch_size = 128\n",
        "end_epsilon = 0.05\n",
        "start_epsilon = 0.9\n",
        "decay_epsilon = 1000\n",
        "\n",
        "\n",
        "input_size = env.action_space.n\n",
        "state, info = env.reset()\n",
        "output_size = len(state)\n",
        "\n",
        "\n",
        "policy_net = Q_network(output_size, input_size).to(device)\n",
        "target_net = Q_network(output_size, input_size).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "optimizer = optim.AdamW(policy_net.parameters(), lr=0.0001, amsgrad=True)\n"
      ],
      "metadata": {
        "id": "rjatDdZ-GB83"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Epsilon épsilon-greedy"
      ],
      "metadata": {
        "id": "MNFv3xd_mt5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_e = 0.9\n",
        "end_e = 0.05\n",
        "decay_e = 1000\n",
        "\n",
        "def select_action(state):\n",
        "    global steps\n",
        "\n",
        "    eps_threshold = end_e + (start_e - end_e) * math.exp(-1. * steps / decay_e)\n",
        "    steps += 1\n",
        "\n",
        "    if random.random() > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "b06YT5-hLDn6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6 Defina la reproducción de la experiencia (experience replay):"
      ],
      "metadata": {
        "id": "n9DbQRIzrTH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class EReplay:\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = []\n",
        "        self.capacity = capacity\n",
        "\n",
        "    # Agregar transicion\n",
        "    def push(self, *args):\n",
        "        if len(self.memory) < self.capacity:\n",
        "          self.memory.append(Transition(*args))\n",
        "\n",
        "    # Obtener sample\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)"
      ],
      "metadata": {
        "id": "HL18_GqXtKNy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMPym7Ul8w7l"
      },
      "source": [
        "\n",
        "# Parte 2. Teoria\n",
        "\n",
        "Defina en qué consiste y en qué clase de problemas se pueden usar cada uno de los siguientes acercamientos en\n",
        "Deep Reinforcement Learning\n",
        "\n",
        "\n",
        "**1. Proximal Policy Optimization**\n",
        "\n",
        "\n",
        "\n",
        "**2. Deep Deterministic Policy Gradients (DDPG)**\n",
        "\n",
        "\n",
        "\n",
        "**3. Trust Region Policy Optimization (TRPO)**\n",
        "\n",
        "\n",
        "\n",
        "**4. Asynchronous Advantage Actor-Critic (A3C)**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}